{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import mysql.connector\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "from cs411_util import generate_graphs, get_pub_info_from_mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAG_CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperId</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>NormalizedTitle</th>\n",
       "      <th>VenueId</th>\n",
       "      <th>DetectedLanguage</th>\n",
       "      <th>DocType</th>\n",
       "      <th>EstimatedCitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2357104884</td>\n",
       "      <td>2002</td>\n",
       "      <td>on the position and function of references in ...</td>\n",
       "      <td>2764343798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2367103297</td>\n",
       "      <td>2003</td>\n",
       "      <td>technology of modeling on multimedia simulatio...</td>\n",
       "      <td>2764343798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2374179795</td>\n",
       "      <td>2001</td>\n",
       "      <td>synchronization after stepout in the exciting ...</td>\n",
       "      <td>2764343798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2382299349</td>\n",
       "      <td>2005</td>\n",
       "      <td>the design for lumping monitored control syste...</td>\n",
       "      <td>2764343798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2378847813</td>\n",
       "      <td>2005</td>\n",
       "      <td>the communication method between ironmaking ma...</td>\n",
       "      <td>2764343798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PaperId  PublishYear                                    NormalizedTitle  \\\n",
       "0  2357104884         2002  on the position and function of references in ...   \n",
       "1  2367103297         2003  technology of modeling on multimedia simulatio...   \n",
       "2  2374179795         2001  synchronization after stepout in the exciting ...   \n",
       "3  2382299349         2005  the design for lumping monitored control syste...   \n",
       "4  2378847813         2005  the communication method between ironmaking ma...   \n",
       "\n",
       "      VenueId DetectedLanguage  DocType  EstimatedCitation  \n",
       "0  2764343798              NaN  Journal                  0  \n",
       "1  2764343798              NaN  Journal                  0  \n",
       "2  2764343798              NaN  Journal                  0  \n",
       "3  2764343798              NaN  Journal                  0  \n",
       "4  2764343798              NaN  Journal                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'MAG_0919_CS/'\n",
    "Papers = data_dir + 'Papers_CS_20190919.tsv'\n",
    "papers_df = pd.read_csv(Papers, sep='\\t')\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5597605/5597605 [00:05<00:00, 1073874.36it/s]\n"
     ]
    }
   ],
   "source": [
    "pid2infos = {item['PaperId'] : {'title' : item['NormalizedTitle'], 'year' : item['PublishYear']} for item in tqdm(papers_df[['PaperId', 'NormalizedTitle', 'PublishYear']].to_dict('records'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperId</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1963479517</td>\n",
       "      <td>This study investigated EFL learners' online r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2095588566</td>\n",
       "      <td>Based on the concept of credibility and a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1963479629</td>\n",
       "      <td>Virtualization technology has shown immense po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1819117914</td>\n",
       "      <td>Serious games have recently emerged as an aven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2095588629</td>\n",
       "      <td>In this paper, we propose an unequal error pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PaperId                                           Abstract\n",
       "0  1963479517  This study investigated EFL learners' online r...\n",
       "1  2095588566  Based on the concept of credibility and a new ...\n",
       "2  1963479629  Virtualization technology has shown immense po...\n",
       "3  1819117914  Serious games have recently emerged as an aven...\n",
       "4  2095588629  In this paper, we propose an unequal error pro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAb = data_dir + 'PAb_CS_20190919.tsv'\n",
    "pab_df = pd.read_csv(PAb, sep='\\t')\n",
    "pab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4541447/4541447 [00:02<00:00, 1539490.33it/s]\n"
     ]
    }
   ],
   "source": [
    "pid2abs = {item['PaperId'] : item['Abstract'] for item in tqdm(pab_df.to_dict('records'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperSeqid</th>\n",
       "      <th>AuthorSeqid</th>\n",
       "      <th>AffiliationSeqid</th>\n",
       "      <th>AuthorSequenceNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1963479517</td>\n",
       "      <td>2167258348</td>\n",
       "      <td>134161618.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1963479517</td>\n",
       "      <td>2506097535</td>\n",
       "      <td>134161618.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1963479517</td>\n",
       "      <td>2296113232</td>\n",
       "      <td>142823887.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2095588566</td>\n",
       "      <td>2439736113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2095588566</td>\n",
       "      <td>2575410839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PaperSeqid  AuthorSeqid  AffiliationSeqid  AuthorSequenceNumber\n",
       "0  1963479517   2167258348       134161618.0                     2\n",
       "1  1963479517   2506097535       134161618.0                     3\n",
       "2  1963479517   2296113232       142823887.0                     1\n",
       "3  2095588566   2439736113               NaN                     2\n",
       "4  2095588566   2575410839               NaN                     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAuAf = data_dir + 'PAuAf_CS_20190919.tsv'\n",
    "pauaf_df = pd.read_csv(PAuAf, sep='\\t')\n",
    "pauaf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15571613/15571613 [00:51<00:00, 301143.28it/s]\n",
      "100%|██████████| 6149660/6149660 [00:17<00:00, 349848.30it/s]\n"
     ]
    }
   ],
   "source": [
    "pid2magfids = defaultdict(list)\n",
    "magfid2pids = defaultdict(list)\n",
    "for item in tqdm(pauaf_df[['PaperSeqid', 'AuthorSeqid']].to_dict('records')):\n",
    "    pid2magfids[item['PaperSeqid']].append(item['AuthorSeqid'])\n",
    "    magfid2pids[item['AuthorSeqid']].append(item['PaperSeqid'])\n",
    "\n",
    "fname2magfids = defaultdict(list)\n",
    "magfid2fname = {}\n",
    "for item in tqdm(pd.read_csv('SeqName_CS_20190919.tsv', sep='\\t', header=None).to_dict('records')):\n",
    "    if item[2] == 'author':\n",
    "        fname2magfids[item[1].lower()].append(item[0])\n",
    "        magfid2fname[item[0]] = item[1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5597605/5597605 [02:19<00:00, 40018.43it/s] \n"
     ]
    }
   ],
   "source": [
    "co_author_graph = nx.Graph()\n",
    "for pid, info in tqdm(pid2infos.items()):\n",
    "    info['abstract'] = pid2abs.get(pid)\n",
    "    co_authors = pid2magfids.get(pid)\n",
    "    info['authors'] = co_authors\n",
    "    for i in range(len(co_authors)):\n",
    "        for j in range(i+1, len(co_authors)):\n",
    "            if not co_author_graph.has_edge(co_authors[i], co_authors[j]):\n",
    "                co_author_graph.add_edge(co_authors[i], co_authors[j], c=0)\n",
    "            co_author_graph.get_edge_data(co_authors[i], co_authors[j])['c'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with open('magfid2pids.pickle', 'wb') as f_out:\n",
    "    pickle.dump(magfid2pids, f_out)\n",
    "with open('pid2magfids.pickle', 'wb') as f_out:\n",
    "    pickle.dump(pid2magfids, f_out)\n",
    "with open('fname2magfids.pickle', 'wb') as f_out:\n",
    "    pickle.dump(fname2magfids, f_out)\n",
    "with open('pid2infos.pickle', 'wb') as f_out:\n",
    "    pickle.dump(pid2infos, f_out)\n",
    "with open('magfid2fname.pickle', 'wb') as f_out:\n",
    "    pickle.dump(magfid2fname, f_out)\n",
    "nx.write_gpickle(co_author_graph, 'co_author.gpickle')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in co_author_graph.nodes:\n",
    "    nbr = list(co_author_graph.neighbors(n))[0]\n",
    "    print((n, nbr))\n",
    "    print(co_author_graph.get_edge_data(n, nbr))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in pid2infos.items():\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in magfid2pids.items():\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AcademicWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('faculty.json') as f_in:\n",
    "    faculty = json.load(f_in)\n",
    "with open('publications.json') as f_in:\n",
    "    publications = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "awfid2pids = {item['id'] : item['publications'] for item in faculty}\n",
    "fname2awfids = defaultdict(list)\n",
    "awfid2fname = {}\n",
    "for item in faculty:\n",
    "    fname2awfids[item['name'].lower()].append(item['id'])\n",
    "    awfid2fname[item['id']] = item['name'].lower()\n",
    "pid2awfids = defaultdict(list)\n",
    "for fid, pids in awfid2pids.items():\n",
    "    for pid in pids:\n",
    "        pid2awfids[pid].append(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('awfid2pids.pickle', 'wb') as f_out:\n",
    "    pickle.dump(awfid2pids, f_out)\n",
    "with open('pid2awfids.pickle', 'wb') as f_out:\n",
    "    pickle.dump(pid2awfids, f_out)\n",
    "with open('fname2awfids.pickle', 'wb') as f_out:\n",
    "    pickle.dump(fname2awfids, f_out)\n",
    "with open('awfid2fname.pickle', 'wb') as f_out:\n",
    "    pickle.dump(awfid2fname, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_author_graph = nx.read_gpickle('co_author.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid2infos = json.load(open('pid2infos.json'))\n",
    "aid2pids = json.load(open('aid2pids.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split publications by year\n",
    "known_pids = {pid for pid, info in pid2infos.items() if info['year'] <= 2016}\n",
    "unknown_pids = {pid for pid, info in pid2infos.items() if info['year'] > 2016}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_authors = [aid for aid, pids in aid2pids.items() if any([pid in known_pids for pid in pids]) and any([pid in unknown_pids for pid in pids])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('allenai-specter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_similarities = []\n",
    "for aid in tqdm(test_authors[:100]):\n",
    "    known_pubs = [pid for pid in aid2pids[aid] if pid in known_pids and pid2infos[pid]['abstract'] is not None]\n",
    "    unknown_pubs = [pid for pid in aid2pids[aid] if pid in unknown_pids and pid2infos[pid]['abstract'] is not None]\n",
    "    if (not known_pubs) or (not unknown_pubs):\n",
    "        continue\n",
    "    known_emb = model.encode(['%s[SEP]%s' % (pid2infos[pid]['title'], pid2infos[pid]['abstract']) for pid in known_pubs], convert_to_tensor=True)\n",
    "    unknown_emb = model.encode(['%s[SEP]%s' % (pid2infos[pid]['title'], pid2infos[pid]['abstract']) for pid in unknown_pubs], convert_to_tensor=True)\n",
    "    search_hits = util.semantic_search(unknown_emb, known_emb, top_k=1)\n",
    "    pos_test_similarities.extend([hit[0]['score'] for hit in search_hits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos_test_similarities))\n",
    "plt.hist(pos_test_similarities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test_similarities = []\n",
    "temp_test_authors = deepcopy(test_authors)\n",
    "random.seed(0)\n",
    "random.shuffle(temp_test_authors)\n",
    "for idx, aid in enumerate(tqdm(temp_test_authors[:100])):\n",
    "    known_pubs = [pid for pid in aid2pids[aid] if pid in known_pids and pid2infos[pid]['abstract'] is not None]\n",
    "    unknown_pubs = [pid for pid in aid2pids[temp_test_authors[idx+1]] if pid in unknown_pids and pid2infos[pid]['abstract'] is not None]\n",
    "    if (not known_pubs) or (not unknown_pubs):\n",
    "        continue\n",
    "    known_emb = model.encode(['%s[SEP]%s' % (pid2infos[pid]['title'], pid2infos[pid]['abstract']) for pid in known_pubs], convert_to_tensor=True)\n",
    "    unknown_emb = model.encode(['%s[SEP]%s' % (pid2infos[pid]['title'], pid2infos[pid]['abstract']) for pid in unknown_pubs], convert_to_tensor=True)\n",
    "    search_hits = util.semantic_search(unknown_emb, known_emb, top_k=1)\n",
    "    neg_test_similarities.extend([hit[0]['score'] for hit in search_hits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(neg_test_similarities))\n",
    "plt.hist(neg_test_similarities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "len([1 for score in pos_test_similarities if score > 0.7]) / len(pos_test_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "len([1 for score in pos_test_similarities if score > 0.7]) / (len([1 for score in pos_test_similarities if score > 0.7]) + len([1 for score in neg_test_similarities if score > 0.7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "(len([1 for score in pos_test_similarities if score > 0.7]) + len([1 for score in neg_test_similarities if score <= 0.7])) / (len(pos_test_similarities) + len(neg_test_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Papers = data_dir + 'PF_CS_20190919.tsv'\n",
    "papers_df = pd.read_csv(Papers, sep='\\t')\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Papers = data_dir + 'PR_CS_20190919.tsv'\n",
    "papers_df = pd.read_csv(Papers, sep='\\t')\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Papers = data_dir + 'Stats_CS_20190919.tsv'\n",
    "papers_df = pd.read_csv(Papers, sep='\\t')\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Papers = data_dir + 'vfi_vector.tsv'\n",
    "papers_df = pd.read_csv(Papers, sep='\\t')\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resources\n",
    "with open('awfid2pids.pickle', 'rb') as f_in:\n",
    "    awfid2pids = pickle.load(f_in)\n",
    "with open('pid2awfids.pickle', 'rb') as f_in:\n",
    "    pid2awfids = pickle.load(f_in)\n",
    "with open('fname2awfids.pickle', 'rb') as f_in:\n",
    "    fname2awfids = pickle.load(f_in)\n",
    "with open('magfid2pids.pickle', 'rb') as f_in:\n",
    "    magfid2pids = pickle.load(f_in)\n",
    "with open('pid2magfids.pickle', 'rb') as f_in:\n",
    "    pid2magfids = pickle.load(f_in)\n",
    "with open('fname2magfids.pickle', 'rb') as f_in:\n",
    "    fname2magfids = pickle.load(f_in)\n",
    "with open('awfid2fname.pickle', 'rb') as f_in:\n",
    "    awfid2fname = pickle.load(f_in)\n",
    "    \n",
    "with open('pid2infos.pickle', 'rb') as f_in:\n",
    "    pid2infos = pickle.load(f_in)\n",
    "with open('magfid2fname.pickle', 'rb') as f_in:\n",
    "    magfid2fname = pickle.load(f_in)\n",
    "    \n",
    "db = mysql.connector.connect(user='mag_readonly', password='j6gi48ch82nd9pff', host=\"mag-2020-09-14.mysql.database.azure.com\",\n",
    "   port=3306,\n",
    "   database='mag_2020_09_14',\n",
    "   ssl_ca=\"DigiCertGlobalRootCA.crt.pem\",\n",
    "   ssl_disabled=False)\n",
    "cursor = db.cursor()\n",
    "\n",
    "sentence_transformer = SentenceTransformer('allenai-specter').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404\n",
      "{'title': 'designing energy efficient convolutional neural networks using energy aware pruning', 'abstract': 'Deep convolutional neural networks (CNNs) are indispensable to state-of-the-art computer vision algorithms. However, they are still rarely deployed on battery-powered mobile devices, such as smartphones and wearable gadgets, where vision algorithms can enable many revolutionary real-world applications. The key limiting factor is the high energy consumption of CNN processing due to its high computational complexity. While there are many previous efforts that try to reduce the CNN model size or the amount of computation, we find that they do not necessarily result in lower energy consumption. Therefore, these targets do not serve as a good metric for energy cost estimation. To close the gap between CNN design and energy consumption optimization, we propose an energy-aware pruning algorithm for CNNs that directly uses the energy consumption of a CNN to guide the pruning process. The energy estimation methodology uses parameters extrapolated from actual hardware measurements. The proposed layer-by-layer pruning algorithm also prunes more aggressively than previously proposed pruning methods by minimizing the error in the output feature maps instead of the filter weights. For each layer, the weights are first pruned and then locally fine-tuned with a closed-form least-square solution to quickly restore the accuracy. After all layers are pruned, the entire network is globally fine-tuned using back-propagation. With the proposed pruning method, the energy consumption of AlexNet and GoogLeNet is reduced by 3.7x and 1.6x, respectively, with less than 1% top-5 accuracy loss. We also show that reducing the number of target classes in AlexNet greatly decreases the number of weights, but has a limited impact on energy consumption.', 'co_author': ['vivienne sze', 'tienju yang', 'yuhsin chen']}\n"
     ]
    }
   ],
   "source": [
    "target_author_name = list(set(fname2awfids.keys()) & set(fname2magfids.keys()))[4]\n",
    "target_author_id = fname2awfids[target_author_name][0]\n",
    "\n",
    "test_pid = -1\n",
    "for fid in fname2magfids[target_author_name]:\n",
    "    try:\n",
    "        for pid in magfid2pids[fid]:\n",
    "            if pid2infos[pid]['abstract'] is not None and len(pid2infos[pid]['authors']) >= 2:\n",
    "                test_pid = pid\n",
    "                break\n",
    "        if test_pid >= 0:\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "if test_pid >= 0:\n",
    "    test_pub = {'title': pid2infos[test_pid]['title'],\n",
    "                'abstract' : pid2infos[test_pid]['abstract'],\n",
    "                'co_author' : [magfid2fname[fid] for fid in pid2infos[test_pid]['authors']]}\n",
    "    print(target_author_id)\n",
    "    print(test_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysql.connector.cursor_cext.CMySQLCursor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999547004699707"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence transformer score\n",
    "known_pids = awfid2pids[target_author_id]\n",
    "known_pubs = get_pub_info_from_mysql(known_pids, cursor)\n",
    "known_emb = sentence_transformer.encode(['%s[SEP]%s' % (str(info.get('title')), str(info.get('abstract'))) for pid, info in known_pubs.items()], convert_to_tensor=True).cuda()\n",
    "unknown_emb = sentence_transformer.encode(['%s[SEP]%s' % (test_pub['title'], test_pub['abstract'])], convert_to_tensor=True).cuda()\n",
    "search_hits = util.semantic_search(unknown_emb, known_emb, top_k=1)\n",
    "semantic_score = search_hits[0][0]['score']\n",
    "semantic_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url='http://128.174.136.27:5000', params={'target' : target_author_id, 'title' : test_pub['title'], 'abstract' : test_pub['abstract']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"belongs\":true,\"score\":0.9999966621398926,\"semantic_score\":0.9999966621398926}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_author = 'Jiawei Han'\n",
    "aw_candidate_ids = fname2awfids.get(co_author.lower())\n",
    "if aw_candidate_ids is not None:\n",
    "    aw_graphs = generate_graphs(aw_candidate_ids, awfid2pids, pid2awfids)\n",
    "\n",
    "mag_candidate_ids = fname2magfids.get(co_author.lower())\n",
    "if mag_candidate_ids is not None:\n",
    "    mag_graphs = generate_graphs(mag_candidate_ids, magfid2pids, pid2magfids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(list(mag_graphs[i].nodes)) for i in range(len(mag_graphs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_graphs[0].nodes[2721444824]['pids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('show databases;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('use mag_2020_09_14;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('show tables;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('describe paperauthoraffiliations;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('describe papers;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143843904, 'thermal aware cad for modern integrated circuits')\n",
      "(1990758031, 'a decap placement methodology for reducing joule heating and temperature in psn interconnect')\n",
      "(2055008360, 'fast thermal aware floorplanning using white space optimization')\n",
      "(2074342132, 'redundant c4 power pin placement to ensure robust power grid delivery')\n",
      "(2121142867, 'package chip co design to increase flip chip c4 reliability')\n",
      "(2122621647, 'a model for rolling swarms of locusts')\n",
      "(2203556365, 'systems and methods for integrated circuit c4 ball placement')\n",
      "(2279021877, 'methods and systems for integrated circuit c4 ball placement')\n",
      "(2983968810, 'aerodynamics of wiffle balls')\n",
      "(3047808303, 'experimental investigation of the aerodynamic forces on a curveball')\n"
     ]
    }
   ],
   "source": [
    "myresult = cursor.fetchall()\n",
    "for x in myresult:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select Abstract from paperabstracts where PaperId in (%s)' % ','.join([str(pid) for pid in mag_graphs[0].nodes[2721444824]['pids']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select PaperId, PaperTitle from papers where PaperId in (%s)' % ','.join([str(pid) for pid in known_pubs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select * from authors where DisplayName=\"Jiawei Han\" limit 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('select * from paperauthoraffiliations where PaperId=21366')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9c7e6a376f2381ce584cd33259e87a1795226bafbf9464c983b7a0ecc23664a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('test2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
